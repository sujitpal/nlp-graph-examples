{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate Stories against KG\n",
    "\n",
    "In this notebook, we will annotate 4 random stories scraped manually from [ScienceDaily.com](https://www.sciencedaily.com/) against a company-proprietary Knowledge Graph (KG).\n",
    "\n",
    "The KG is provided as a TSV file of nodes (concepts) and edges (relationships). We will use the node file to construct a data structure, called an automaton, to support the [Aho-Corasick algorithm](https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm). Conceptually, the data structure maps concept names (and synonyms) to the concept ID. As an article text is streamed against it, the algorithm will capture the text spans that match the concept names in the structure.\n",
    "\n",
    "Output is a single TSV file containing the story ID, the concept ID, and the number of times the concept ID was found in the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ahocorasick\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "VERTEX_FILEPATH = os.path.join(DATA_DIR, \"emmet-vertices.tsv\")\n",
    "CONCEPTMAP_FILEPATH = os.path.join(DATA_DIR, \"story-concepts.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Aho-Corasick Automaton\n",
    "\n",
    "We filter out `qualifier` and `event` type concepts since they are somewhat noisy. We also remove acronyms that are 2 characters or less in size. Both are attempts to reduce noisy matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_annotator(vertices_file):\n",
    "    A = ahocorasick.Automaton()\n",
    "    fvert = open(vertices_file, \"r\")\n",
    "    for line in fvert:\n",
    "        cols = line.strip().split('\\t')\n",
    "        if len(cols) != 5:\n",
    "            continue\n",
    "        if cols[-1] == \"qualifier\" or cols[-1] == \"event\":\n",
    "            continue\n",
    "        cid = cols[0]\n",
    "        syns = cols[1]\n",
    "        for syn in syns.split('|'):\n",
    "            if len(syn) < 3:\n",
    "                continue\n",
    "            A.add_word(syn, (cid, syn))\n",
    "\n",
    "    fvert.close()\n",
    "    A.make_automaton()    \n",
    "    return A\n",
    "\n",
    "annotator = build_annotator(VERTEX_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Story, Annotate, Write Concept Frequencies\n",
    "\n",
    "We loop through each `.story` file, reading the text and doing some cleanup on it. \n",
    "\n",
    "The `get_story_text` function reads each file, and performs some basic clean-up, mainly removing punctuations from the text. The other thing is to put a leading and trailing space in the text, this is to support the whole word condition in the `annotate_text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story_text(story_file):\n",
    "    text_lines = []\n",
    "    ftext = open(os.path.join(DATA_DIR, story_file))\n",
    "    for line in ftext:\n",
    "        text_lines.append(line.strip())\n",
    "    ftext.close()\n",
    "    text = \" \".join(text_lines)\n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # add space in front and back (for word check below)\n",
    "    text = \" \" + text + \"  \"\n",
    "    return text\n",
    "\n",
    "\n",
    "def annotate_text(annotator, text, debug=False):\n",
    "    matched_concepts = {}\n",
    "    for end_index, (idx, orig_value) in annotator.iter(text):\n",
    "        # make sure word identified is not part of another word\n",
    "        start_index = end_index - len(orig_value) + 1\n",
    "        if text[start_index - 1] != ' ' or text[end_index + 2] != ' ':\n",
    "            continue\n",
    "        if debug:\n",
    "            print(start_index, end_index, idx, orig_value)\n",
    "        if idx in matched_concepts.keys():\n",
    "            matched_concepts[idx] += 1\n",
    "        else:\n",
    "            matched_concepts[idx] = 1\n",
    "    concept_counts = sorted(\n",
    "        [(k, matched_concepts[k]) for k in matched_concepts.keys()],\n",
    "        key=operator.itemgetter(1), reverse=True)\n",
    "    return concept_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 190823140729.story...\n",
      "Processing 190904194433.story...\n",
      "Processing 190909193211.story...\n",
      "Processing 190916092109.story...\n"
     ]
    }
   ],
   "source": [
    "fconcepts = open(CONCEPTMAP_FILEPATH, \"w\")\n",
    "for story_filename in os.listdir(DATA_DIR):\n",
    "    if not story_filename.endswith(\".story\"):\n",
    "        continue\n",
    "    print(\"Processing {:s}...\".format(story_filename))\n",
    "    story_id = story_filename.split('.')[0]\n",
    "    text = get_story_text(os.path.join(DATA_DIR, story_filename))\n",
    "    concept_map = annotate_text(annotator, text)\n",
    "    for cid, count in concept_map:\n",
    "        fconcepts.write(\"{:s}\\t{:s}\\t{:d}\\n\".format(story_id, cid, count))\n",
    "\n",
    "fconcepts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190823140729</td>\n",
       "      <td>8001550</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190823140729</td>\n",
       "      <td>9199226</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190823140729</td>\n",
       "      <td>2795416</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190823140729</td>\n",
       "      <td>9790284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190823140729</td>\n",
       "      <td>8837843</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       story_id  concept_id  concept_count\n",
       "0  190823140729     8001550             15\n",
       "1  190823140729     9199226              3\n",
       "2  190823140729     2795416              2\n",
       "3  190823140729     9790284              2\n",
       "4  190823140729     8837843              2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_concepts_df = pd.read_csv(CONCEPTMAP_FILEPATH,\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"story_id\", \"concept_id\", \"concept_count\"])\n",
    "story_concepts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
